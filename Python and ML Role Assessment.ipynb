{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b393b5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\saloni priya\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Collecting dlib\n",
      "  Using cached dlib-19.24.6.tar.gz (3.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting face_recognition\n",
      "  Obtaining dependency information for face_recognition from https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\saloni priya\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Using cached face_recognition_models-0.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\saloni priya\\anaconda3\\lib\\site-packages (from face_recognition) (8.0.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\saloni priya\\anaconda3\\lib\\site-packages (from face_recognition) (9.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\saloni priya\\anaconda3\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for dlib\n",
      "Failed to build dlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [41 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  \n",
      "  ================================================================================\n",
      "  ================================================================================\n",
      "  ================================================================================\n",
      "  \n",
      "                     CMake is not installed on your system!\n",
      "  \n",
      "      Or it is possible some broken copy of cmake is installed on your system.\n",
      "      It is unfortunately very common for python package managers to include\n",
      "      broken copies of cmake.  So if the error above this refers to some file\n",
      "      path to a cmake file inside a python or anaconda or miniconda path then you\n",
      "      should delete that broken copy of cmake from your computer.\n",
      "  \n",
      "      Instead, please get an official copy of cmake from one of these known good\n",
      "      sources of an official cmake:\n",
      "          - cmake.org (this is how windows users should get cmake)\n",
      "          - apt install cmake (for Ubuntu or Debian based systems)\n",
      "          - yum install cmake (for Redhat or CenOS based systems)\n",
      "  \n",
      "      On a linux machine you can run `which cmake` to see what cmake you are\n",
      "      actually using.  If it tells you it's some cmake from any kind of python\n",
      "      packager delete it and install an official cmake.\n",
      "  \n",
      "      More generally, cmake is not installed if when you open a terminal window\n",
      "      and type\n",
      "         cmake --version\n",
      "      you get an error.  So you can use that as a very basic test to see if you\n",
      "      have cmake installed.  That is, if cmake --version doesn't run from the\n",
      "      same terminal window from which you are reading this error message, then\n",
      "      you have not installed cmake.  Windows users should take note that they\n",
      "      need to tell the cmake installer to add cmake to their PATH.  Since you\n",
      "      can't run commands that are not in your PATH.  This is how the PATH works\n",
      "      on Linux as well, but failing to add cmake to the PATH is a particularly\n",
      "      common problem on windows and rarely a problem on Linux.\n",
      "  \n",
      "  ================================================================================\n",
      "  ================================================================================\n",
      "  ================================================================================\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for dlib\n",
      "ERROR: Could not build wheels for dlib, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python dlib face_recognition numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "940ae410",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mface_recognition\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9923d0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m             known_face_names\u001b[38;5;241m.\u001b[39mappend(person_name)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Load and encode the images\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m load_and_encode_images(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36mload_and_encode_images\u001b[1;34m(dataset_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_encode_images\u001b[39m(dataset_path):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m person_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(dataset_path):\n\u001b[0;32m      6\u001b[0m         person_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_path, person_name)\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(person_path):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "def load_and_encode_images(dataset_path):\n",
    "    for person_name in os.listdir(dataset_path):\n",
    "        person_path = os.path.join(dataset_path, person_name)\n",
    "        if not os.path.isdir(person_path):\n",
    "            continue\n",
    "\n",
    "        for image_name in os.listdir(person_path):\n",
    "            image_path = os.path.join(person_path, image_name)\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            encoding = face_recognition.face_encodings(image)[0]\n",
    "            known_face_encodings.append(encoding)\n",
    "            known_face_names.append(person_name)\n",
    "\n",
    "# Load and encode the images\n",
    "load_and_encode_images(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26395c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_recognize_faces(image_path):\n",
    "    # Load the image\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    \n",
    "    # Detect faces\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    \n",
    "    # Encode the detected faces\n",
    "    face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "    \n",
    "    # Initialize an array for face names\n",
    "    face_names = []\n",
    "    \n",
    "    for face_encoding in face_encodings:\n",
    "        # Compare the detected face encoding with known encodings\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7f1284",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:9\u001b[1;36m\u001b[0m\n\u001b[1;33m    return face_locations, face_names\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    " # Find the best match\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "        \n",
    "        face_names.append(name)\n",
    "    \n",
    "    return face_locations, face_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0079b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_detected_faces(image_path, face_locations, face_names):\n",
    "    image = cv2.imread(image_path)\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw a label with the name below the face\n",
    "        cv2.rectangle(image, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(image, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "    \n",
    "    # Display the output\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1eb1553",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face_recognition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Example test set with true labels\u001b[39;00m\n\u001b[0;32m     15\u001b[0m test_images \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     16\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_images/person1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperson1\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     17\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_images/person2.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperson2\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     18\u001b[0m ]\n\u001b[1;32m---> 20\u001b[0m evaluate_model(test_images)\n",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(test_images)\u001b[0m\n\u001b[0;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path, true_label \u001b[38;5;129;01min\u001b[39;00m test_images:\n\u001b[1;32m----> 6\u001b[0m     _, detected_names \u001b[38;5;241m=\u001b[39m detect_and_recognize_faces(image_path)\n\u001b[0;32m      8\u001b[0m     y_true\u001b[38;5;241m.\u001b[39mextend([true_label] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(detected_names))\n\u001b[0;32m      9\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mextend(detected_names)\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36mdetect_and_recognize_faces\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_and_recognize_faces\u001b[39m(image_path):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Load the image\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     image \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mload_image_file(image_path)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Detect faces\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     face_locations \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_locations(image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'face_recognition' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_model(test_images):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for image_path, true_label in test_images:\n",
    "        _, detected_names = detect_and_recognize_faces(image_path)\n",
    "        \n",
    "        y_true.extend([true_label] * len(detected_names))\n",
    "        y_pred.extend(detected_names)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Example test set with true labels\n",
    "test_images = [\n",
    "    (\"test_images/person1.jpg\", \"person1\"),\n",
    "    (\"test_images/person2.jpg\", \"person2\"),\n",
    "]\n",
    "\n",
    "evaluate_model(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "987fe543",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming y_true and y_pred are lists of true and predicted labels\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_true, y_pred)\n\u001b[0;32m      5\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming y_true and y_pred are lists of true and predicted labels\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26b8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
